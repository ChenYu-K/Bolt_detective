{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import os\n",
    "import cv2 as cv\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch.autograd import Variable"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Define the data and label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def getlabel(dir):\n",
    "    labels=[]\n",
    "    for name in os.listdir(dir):\n",
    "        if os.path.splitext(name)[1] == '.JPG':\n",
    "            fname=os.path.splitext(name)[0]\n",
    "            fname=fname.split('-')[1]\n",
    "            labels.append(fname)\n",
    "    labels = list(map(float, labels))\n",
    "    labels = torch.tensor(labels)\n",
    "    # Normalize labels\n",
    "    #min = torch.min(labels)\n",
    "    #max = torch.max(labels)\n",
    "    #labels = (labels - min) / (max - min)\n",
    "    #labels = labels/300\n",
    "    labels = labels.type(torch.FloatTensor)\n",
    "    labels = labels.unsqueeze(1)\n",
    "    return labels\n",
    "\n",
    "def generate_dataset(dir):\n",
    "    \"\"\"\n",
    "    set_label should be 'torch.tensor([1])' if two-catogory and positive sample\n",
    "    \"\"\"\n",
    "    train_data = []\n",
    "    for file_name in os.listdir(dir):\n",
    "        if file_name != \"Thumbs.db\":\n",
    "            img_dir = os.path.join(dir, file_name)\n",
    "            img = cv.imread(img_dir)\n",
    "            #img = cv.resize(img, (769, 432))   # /5 resize img\n",
    "            #img_gray = cv.cvtColor(img,cv.COLOR_RGB2GRAY)\n",
    "            pimg = Image.fromarray(img)\n",
    "            train_data.append(pimg)\n",
    "    return train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "traindir= './train/'\n",
    "validdir = './valid/'\n",
    "train_data0 = generate_dataset(traindir)\n",
    "train_label0=getlabel(traindir)\n",
    "valid_data0 = generate_dataset(validdir)\n",
    "valid_label0 = getlabel(validdir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_label0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 重写dataset类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data, labels, transform=None, target_transform=None):\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        imgs = []\n",
    "        for i in range(len(labels)):\n",
    "            # print(type(data[i]))    # <class 'PIL.Image.Image'>\n",
    "            im_tensor = transform(data[i])#.to(torch.device(\"cpu\"))\n",
    "            imgs.append((im_tensor, labels[i]))\n",
    "        self.imgs = imgs                         # DataLoader通过getitem读取图片数据\n",
    "    def __getitem__(self, index):\n",
    "        fn, label = self.imgs[index]\n",
    "        return fn, label\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 用MyDataset构建数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\"\"\"\"\"\n",
    "transform = transforms.Compose(\n",
    "    [transforms.Grayscale(num_output_channels=1), #彩色图像转灰度图像num_output_channels默认1\n",
    "    transforms.ToTensor(),  # range [0, 255] -> [0.0,1.0]   \n",
    "    #transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "\"\"\"\"\"\n",
    "\n",
    "# 也可以再定义train_transform加入一些数据增强 \n",
    "train_data = MyDataset(train_data0, train_label0, transform=transform)\n",
    "valid_data = MyDataset(valid_data0, valid_label0, transform=transform)\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=10, shuffle=True)\n",
    "valid_loader = DataLoader(dataset=valid_data, batch_size=10, shuffle=True)\n",
    "dataiter=iter(train_loader)\n",
    "images, labels = dataiter.next()\n",
    "print(images.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_label0.data.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 定义网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# todo Bottleneck\n",
    "class Bottleneck(nn.Module):\n",
    "    \"\"\"\n",
    "    __init__\n",
    "        in_channel：残差块输入通道数\n",
    "        out_channel：残差块输出通道数\n",
    "        stride：卷积步长\n",
    "        downsample：在_make_layer函数中赋值，用于控制shortcut图片下采样 H/2 W/2\n",
    "    \"\"\"\n",
    "    expansion = 4   # 残差块第3个卷积层的通道膨胀倍率\n",
    "    def __init__(self, in_channel, out_channel, stride=1, downsample=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=in_channel, out_channels=out_channel, kernel_size=1, stride=1, bias=False)   # H,W不变。C: in_channel -> out_channel\n",
    "        self.bn1 = nn.BatchNorm2d(num_features=out_channel)\n",
    "        self.conv2 = nn.Conv2d(in_channels=out_channel, out_channels=out_channel, kernel_size=3, stride=stride, bias=False, padding=1)  # H/2，W/2。C不变\n",
    "        self.bn2 = nn.BatchNorm2d(num_features=out_channel)\n",
    "        self.conv3 = nn.Conv2d(in_channels=out_channel, out_channels=out_channel*self.expansion, kernel_size=1, stride=1, bias=False)   # H,W不变。C: out_channel -> 4*out_channel\n",
    "        self.bn3 = nn.BatchNorm2d(num_features=out_channel*self.expansion)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.downsample = downsample\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x    # 将原始输入暂存为shortcut的输出\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)   # 如果需要下采样，那么shortcut后:H/2，W/2。C: out_channel -> 4*out_channel(见ResNet中的downsample实现)\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        out += identity     # 残差连接\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def forward(self, x):\n",
    "    identity = x    # 将原始输入暂存为shortcut的输出\n",
    "    if self.downsample is not None:\n",
    "        identity = self.downsample(x)   # 如果需要下采样，那么shortcut后:H/2，W/2。C: out_channel -> 4*out_channel"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    \"\"\"\n",
    "    __init__\n",
    "        block: 堆叠的基本模块\n",
    "        block_num: 基本模块堆叠个数,是一个list,对于resnet50=[3,4,6,3]\n",
    "        num_classes: 全连接之后的分类特征维度\n",
    "\n",
    "    _make_layer\n",
    "        block: 堆叠的基本模块\n",
    "        channel: 每个stage中堆叠模块的第一个卷积的卷积核个数，对resnet50分别是:64,128,256,512\n",
    "        block_num: 当期stage堆叠block个数\n",
    "        stride: 默认卷积步长\n",
    "    \"\"\"\n",
    "    def __init__(self, block, block_num, num_classes):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_channel = 64    # conv1的输出维度\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=self.in_channel, kernel_size=7, stride=2, padding=3, bias=False)     # H/2,W/2。C:3->64\n",
    "        self.bn1 = nn.BatchNorm2d(self.in_channel)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)     # H/2,W/2。C不变\n",
    "        self.layer1 = self._make_layer(block=block, channel=64, block_num=block_num[0], stride=1)   # H,W不变。downsample控制的shortcut，out_channel=64x4=256\n",
    "        self.layer2 = self._make_layer(block=block, channel=128, block_num=block_num[1], stride=2)  # H/2, W/2。downsample控制的shortcut，out_channel=128x4=512\n",
    "        self.layer3 = self._make_layer(block=block, channel=256, block_num=block_num[2], stride=2)  # H/2, W/2。downsample控制的shortcut，out_channel=256x4=1024\n",
    "        self.layer4 = self._make_layer(block=block, channel=512, block_num=block_num[3], stride=2)  # H/2, W/2。downsample控制的shortcut，out_channel=512x4=2048\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1,1))  # 将每张特征图大小->(1,1)，则经过池化后的输出维度=通道数\n",
    "        self.fc1 = nn.Linear(in_features=512*block.expansion, out_features=1024) #in=2048,out=1024\n",
    "        self.fc2 = nn.Linear(in_features=1024, out_features=512) #in=1024, out=512\n",
    "        self.fc3 = nn.Linear(in_features=512, out_features=num_classes) #in=512, out=1\n",
    "\n",
    "        for m in self.modules():    # 权重初始化\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "\n",
    "    def _make_layer(self, block, channel, block_num, stride=1):\n",
    "        downsample = None   # 用于控制shorcut路的\n",
    "        if stride != 1 or self.in_channel != channel*block.expansion:   # 对resnet50：conv2中特征图尺寸H,W不需要下采样/2，但是通道数x4，因此shortcut通道数也需要x4。对其余conv3,4,5，既要特征图尺寸H,W/2，又要shortcut维度x4\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=self.in_channel, out_channels=channel*block.expansion, kernel_size=1, stride=stride, bias=False), # out_channels决定输出通道数x4，stride决定特征图尺寸H,W/2\n",
    "                nn.BatchNorm2d(num_features=channel*block.expansion))\n",
    "\n",
    "        layers = []  # 每一个convi_x的结构保存在一个layers列表中，i={2,3,4,5}\n",
    "        layers.append(block(in_channel=self.in_channel, out_channel=channel, downsample=downsample, stride=stride)) # 定义convi_x中的第一个残差块，只有第一个需要设置downsample和stride\n",
    "        self.in_channel = channel*block.expansion   # 在下一次调用_make_layer函数的时候，self.in_channel已经x4\n",
    "\n",
    "        for _ in range(1, block_num):  # 通过循环堆叠其余残差块(堆叠了剩余的block_num-1个)\n",
    "            layers.append(block(in_channel=self.in_channel, out_channel=channel))\n",
    "\n",
    "        return nn.Sequential(*layers)   # '*'的作用是将list转换为非关键字参数传入\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Res18"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self,channels):\n",
    "        super(ResidualBlock,self).__init__()\n",
    "        self.channels = channels\n",
    "        self.conv1 = nn.Conv2d(channels,channels,kernel_size=3,padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(channels)\n",
    "        self.conv2 = nn.Conv2d(channels,channels,kernel_size=3,padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(channels)\n",
    "\n",
    "    def forward(self,x):\n",
    "        y = self.conv1(x)\n",
    "        y = F.relu(self.bn1(y))\n",
    "        y = self.conv2(y)\n",
    "        y = F.relu(self.bn2(y))\n",
    "        return F.relu(x+y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    # Net类的初始化函数\n",
    "    def __init__(self):\n",
    "        # 继承父类的初始化函数\n",
    "        super(Net, self).__init__()\n",
    "        # 网络的隐藏层创建，名称可以随便起\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=3, kernel_size=10, stride=2)\n",
    "        self.bn1 = nn.BatchNorm2d(3)\n",
    "        self.conv2 = nn.Conv2d(in_channels=3, out_channels=6, kernel_size=10, stride=2,padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(6)\n",
    "        self.conv3 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5, stride=1)\n",
    "        self.bn3 = nn.BatchNorm2d(12)\n",
    "        #residual\n",
    "        self.rblock1 = ResidualBlock(12)\n",
    "        self.conv4 = nn.Conv2d(in_channels=12, out_channels=24, kernel_size=3, stride=1)\n",
    "        self.bn4 = nn.BatchNorm2d(24)\n",
    "        self.rblock2 = ResidualBlock(24)\n",
    "        self.conv5 = nn.Conv2d(in_channels=24, out_channels=48, kernel_size=2, stride=1)\n",
    "        self.bn5 = nn.BatchNorm2d(48)\n",
    "        self.rblock3 = ResidualBlock(48)\n",
    "        self.conv6 = nn.Conv2d(in_channels=48, out_channels=96, kernel_size=2, stride=1)\n",
    "        self.bn6 = nn.BatchNorm2d(96)\n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "        self.fc1 = nn.Linear(96*8*8, 3072)\n",
    "        self.fc2 = nn.Linear(3072,500)\n",
    "        self.fc3 = torch.nn.Linear(500, 100)\n",
    "        # 输出层(预测层)创建，接收来自隐含层的数据\n",
    "        self.predict_layer = torch.nn.Linear(100, 1)\n",
    "\n",
    "    # 网络的前向传播函数，构造计算图\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))     #(2400-10)/2+1=1196\n",
    "        x = self.pool(x)                        #1196/2=598\n",
    "        x = F.relu(self.bn2(self.conv2(x)))     #(598+2-10)/2+1=296\n",
    "        x = self.pool(x)                        #296/2=148\n",
    "        x = F.relu(self.bn3(self.conv3(x)))     #(148-5)/1+1=144\n",
    "        x = self.pool(x)                        #144/2=72\n",
    "        x = self.rblock1(x)\n",
    "        x = F.relu(self.bn4(self.conv4(x)))     #(72-3)/1+1=70\n",
    "        x = self.pool(x)                        #70/2=35\n",
    "        x = self.rblock2(x)\n",
    "        x = F.relu(self.bn5(self.conv5(x)))     #(35-2)/1+1=34\n",
    "        x = self.pool(x)                        #34/2=17\n",
    "        x = self.rblock3(x)\n",
    "        x = F.relu(self.bn6(self.conv6(x)))     #17-2+1=16\n",
    "        x = self.pool(x)                        #16/2=8\n",
    "        x = x.view(-1, 96*8*8)\n",
    "        # 用relu函数处理隐含层输出的结果并传给输出层\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        predict_result = self.predict_layer(x)\n",
    "        return predict_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def testAccuracy():\n",
    "    \n",
    "    net.eval()\n",
    "    accuracy = 0.0\n",
    "    total = 0.0\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    #device = torch.device(\"cpu\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in valid_loader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            # run the model on the test set to predict labels\n",
    "            outputs = net(images)\n",
    "            # the label with the highest energy will be our prediction\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            accuracy += (predicted == labels).sum().item()\n",
    "    \n",
    "    # compute the accuracy over all test images\n",
    "    accuracy = (100 * accuracy / total)\n",
    "    return(accuracy)\n",
    "\n",
    "def train(num_epochs,device):\n",
    "    import time\n",
    "    start_time = time.process_time()\n",
    "    best_accuracy = 0.0\n",
    "\n",
    "    # Define your execution device\n",
    "    #device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    #device = torch.device(\"cpu\")\n",
    "\n",
    "    predata=[]\n",
    "    labeldata=[]\n",
    "    mseloss=[]\n",
    "    trainnum=[]\n",
    "    # Convert model parameters and buffers to CPU or Cuda\n",
    "    net.to(device)\n",
    "    for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
    "        running_loss = 0.0\n",
    "        running_acc = 0.0\n",
    "\n",
    "        for i, (images, labels) in enumerate(train_loader, 0):\n",
    "            #images, labels = dataiter.next()\n",
    "            # 输入数据进行预测\n",
    "            # get the inputs\n",
    "            images = Variable(images.to(device))\n",
    "            labels = Variable(labels.to(device))\n",
    "            prediction = net(images)\n",
    "            #print(prediction,labels)\n",
    "            #print('Prediction data is:',prediction.data.cpu().numpy()[0])\n",
    "            #print('label data is: ',labels.data.cpu().numpy())\n",
    "            # 计算预测值与真值误差，注意参数顺序问题\n",
    "            # 第一个参数为预测值，第二个为真值\n",
    "            loss = loss_func(prediction, labels)\n",
    "            # 开始优化步骤\n",
    "            # 每次开始优化前将梯度置为0\n",
    "            optimizer.zero_grad()\n",
    "            # 误差反向传播\n",
    "            loss.backward()\n",
    "            # 按照最小loss优化参数\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            if (i+1) % 10 == 0:\n",
    "                # print every 1000 (twice per epoch)\n",
    "                #print(f\"epoch #{epoch+1} Iteration #{i+1} loss: {loss_value}\")\n",
    "                print('[%d, %5d] loss: %.3f' %\n",
    "                      (epoch + 1, i + 1, running_loss / 10))\n",
    "                mseloss.append(running_loss/10)\n",
    "                trainnum.append((i+1)*(epoch+1))\n",
    "                # zero the loss\n",
    "                running_loss = 0.0\n",
    "            predata.append(prediction.data.cpu().numpy()[0])\n",
    "            labeldata.append(labels.data.cpu().numpy()[0])\n",
    "\n",
    "        #accuracy = testAccuracy()\n",
    "        #print('For epoch', epoch+1,'the test accuracy over the whole test set is %d %%' % (accuracy))\n",
    "\n",
    "\n",
    "    print('Finished Training')\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot()\n",
    "    plt.grid(True)\n",
    "    plt.ylim(0,205)\n",
    "    plt.xlim(0,205)\n",
    "    plt.plot(train_label0.data.numpy(), train_label0.data.numpy(), c='Red', lw='3')\n",
    "    plt.scatter(predata,labeldata)\n",
    "    plt.text(0.5, 0, 'Loss=%.4f' % loss.data.cpu().numpy(), fontdict={'size': 20, 'color':  'red'})\n",
    "\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.ylim(0,5)\n",
    "    plt.ylabel(\"Mean Squared Error\")\n",
    "    plt.xlabel(\"train times\")\n",
    "    plt.plot(trainnum,mseloss)\n",
    "\n",
    "\n",
    "    end_time = time.process_time()\n",
    "    print(\"Use time:\", end_time-start_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "Vdataiter=iter(valid_loader)\n",
    "vimg, vlabels = Vdataiter.next()\n",
    "print(vimg.shape)\n",
    "print(vlabels.shape)\n",
    "print(vlabels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 预测结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def predict(model, device,dataloder):\n",
    "    Vdataiter=iter(dataloder)\n",
    "    vimg, vlabels = Vdataiter.next()\n",
    "    model.to(device)\n",
    "    with torch.no_grad():\n",
    "        vimg=vimg.to(device)\n",
    "        out = model(vimg)\n",
    "        #_, pre = torch.max(out.data, 1)\n",
    "        return out, vlabels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 定义模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 输入输出的数据维度，这里都是1维\n",
    "INPUT_FEATURE_DIM = 5000\n",
    "# 隐含层中神经元的个数\n",
    "#NEURON_NUM = 500\n",
    "#OUTPUT_FEATURE_DIM = 1\n",
    "# 学习率，越大学的越快，但也容易造成不稳定，准确率上下波动的情况\n",
    "LEARNING_RATE = 0.00025\n",
    "\n",
    "# 定义模型\n",
    "#net = Net()\n",
    "net = ResNet(block=Bottleneck, block_num=[3,4,6,3],num_classes=1)\n",
    "print(net)\n",
    "# 训练网络\n",
    "# 这里也可以使用其它的优化方法\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=LEARNING_RATE)\n",
    "# 定义一个误差计算方法\n",
    "loss_func = torch.nn.MSELoss() # 定义交叉熵损失函数 交叉熵损失函数是用来衡量两个概率分布之间的距离的#nn.MSELoss()\n",
    "# Define the loss function with Classification Cross-Entropy loss and an optimizer with Adam optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 主函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    " # Vdataiter=iter(valid_loader)\n",
    "# vimg, vlabels = Vdataiter.next()\n",
    "# print(vimg.shape)\n",
    "# print(vlabels.shape)\n",
    "# print(vlabels)\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    #device = torch.device(\"cpu\")\n",
    "    # Let's build our model\n",
    "    train(1000,device)\n",
    "    print('Finished Training')\n",
    "    #Epochごとのlossの保存\n",
    "    torch.save(net, 'preloadnet.pt')\n",
    "\n",
    "    # Test which classes performed well\n",
    "    testAccuracy()\n",
    "    \n",
    "    # Let's load the model we just created and test the accuracy per label\n",
    "    # model = net()\n",
    "    # path = \"myFirstModel.pth\"\n",
    "    # model.load_state_dict(torch.load(path))\n",
    "\n",
    "    plt.figure()\n",
    "    predata, labedata = predict(net, device,valid_loader)\n",
    "    plt.xlim(0,205)\n",
    "    plt.ylim(0,205)\n",
    "    plt.scatter(predata.data.cpu().numpy(),labedata.data.cpu().numpy())\n",
    "    plt.plot(train_label0.data.numpy(), train_label0.data.numpy(), c='Red', lw='3')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Get the predecdata"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x=[]\n",
    "y=[]\n",
    "np.array(x)\n",
    "np.array(y)\n",
    "# net=torch.load('')\n",
    "for i, (images, labels) in enumerate(valid_loader, 0):\n",
    "    #images, labels = dataiter.next()\n",
    "    # 输入数据进行预测\n",
    "    # get the inputs\n",
    "    images = Variable(images.to(device))\n",
    "    labels = Variable(labels.to(device))\n",
    "    predata, labedata = predict(net, 'cpu',valid_loader)\n",
    "    x=np.append(x,[i[0] for i in labedata.data.cpu().numpy()])\n",
    "    y=np.append(y,np.array([i[0] for i in predata.data.cpu().numpy()]))\n",
    "\n",
    "x0=x\n",
    "y0=y"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "x=np.linspace(0,226,200)\n",
    "y=np.linspace(0,226,200)\n",
    "\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy import stats\n",
    "import uncertainties.unumpy as unp\n",
    "import uncertainties as unc\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.xlim(0,226)\n",
    "plt.ylim(0,226)\n",
    "y_err1=1.1*train_label0.data.cpu().numpy()\n",
    "y_err2=0.9*train_label0.data.cpu().numpy()\n",
    "n = len(y)\n",
    "\n",
    "print(x)\n",
    "\n",
    "\n",
    "def f(x, a, b):\n",
    "    return np.multiply(a, x) + b\n",
    "popt, pcov = curve_fit(f, x, y)\n",
    "\n",
    "# retrieve parameter values\n",
    "a = popt[0]\n",
    "b = popt[1]\n",
    "print('Optimal Values')\n",
    "print('a: ' + str(a))\n",
    "print('b: ' + str(b))\n",
    "\n",
    "# compute r^2\n",
    "r2 = 1.0-(sum((y0-f(x0,a,b))**2.0)/((n-1.0)*np.var(y,ddof=1)))\n",
    "print('R^2: ' + str(r2))\n",
    "\n",
    "# plot data\n",
    "\n",
    "plt.scatter(x0,y0,alpha=0.5, label='Data')\n",
    "\n",
    "# calculate regression confidence interval\n",
    "px=np.linspace(0,226,200)\n",
    "py=a*px+b\n",
    "nom = unp.nominal_values(py)\n",
    "std = unp.std_devs(py)\n",
    "\n",
    "def predband(x, xd, yd, p, func, conf=0.95):\n",
    "    # x = requested points\n",
    "    # xd = x data\n",
    "    # yd = y data\n",
    "    # p = parameters\n",
    "    # func = function name\n",
    "    alpha = 1.0 - conf    # significance\n",
    "    N = xd.size          # data sample size\n",
    "    var_n = len(p)  # number of parameters\n",
    "    # Quantile of Student's t distribution for p=(1-alpha/2)\n",
    "    q = stats.t.ppf(1.0 - alpha / 2.0, N - var_n)\n",
    "    # Stdev of an individual measurement\n",
    "    se = np.sqrt(1. / (N - var_n) * \\\n",
    "                 np.sum((yd - func(xd, *p)) ** 2))\n",
    "    # Auxiliary definitions\n",
    "    sx = (x - xd.mean()) ** 2\n",
    "    sxd = np.sum((xd - xd.mean()) ** 2)\n",
    "    # Predicted values (best-fit model)\n",
    "    yp = func(x, *p)\n",
    "    # Prediction band\n",
    "    dy = q * se * np.sqrt(1.0+ (1.0/N) + (sx/sxd))\n",
    "    # Upper & lower prediction bands.\n",
    "    lpb, upb = yp - dy, yp + dy\n",
    "    return lpb, upb\n",
    "\n",
    "#plt.fill_between(df['temperature'], predictions['obs_ci_lower'], predictions['obs_ci_upper'], alpha=.1, label='Prediction interval')\n",
    "# prediction band (95% confidence)\n",
    "\n",
    "# plot the regression\n",
    "plt.plot(px, nom, c='black', label='y=a x + b')\n",
    "\n",
    "# # uncertainty lines (95% confidence)\n",
    "# plt.plot(px, nom - 1.96 * std, c='orange',\\\n",
    "#          label='95% Confidence Region')\n",
    "# plt.plot(px, nom + 1.96 * std, c='orange')\n",
    "\n",
    "lpb, upb = predband(px, x0, y0, popt, f, conf=0.95)\n",
    "\n",
    "lpb=[x+25 for x in px]\n",
    "upb=[x-25 for x in px]\n",
    "\n",
    "plt.plot(px, lpb, 'k--',label='95% Prediction Band')\n",
    "plt.plot(px, upb, 'k--')\n",
    "plt.fill_between(px,lpb,upb, alpha=.1, label='Prediction interval')\n",
    "plt.plot(train_label0.data.numpy(), train_label0.data.numpy(), c='Red')\n",
    "\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel('Label data',fontsize=16)\n",
    "plt.ylabel('Prediction data',fontsize=16)\n",
    "text='$R^2$: {:.2f}'.format(r2)\n",
    "#plt.text(180,20,text)\n",
    "plt.savefig('predictpreload.png', dpi=1200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# bolt detec"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#bolt preload detect\n",
    "\n",
    "bdetecpath='./bdetec/'\n",
    "bdetec_data0 = generate_dataset(bdetecpath)\n",
    "bdetec_label0 = getlabel(bdetecpath)\n",
    "bdetec_data = MyDataset(bdetec_data0, bdetec_label0, transform=transform)\n",
    "bdetec_loader = DataLoader(dataset=bdetec_data, batch_size=1, shuffle=True)\n",
    "\n",
    "#datasetのクラス指定\n",
    "dataset_class=['person', 'traffic light', 'train', 'traffic sign', 'rider', 'car', 'bike', 'motor', 'truck', 'bolt']\n",
    "#表示したいラベルの色の指定\n",
    "#注意！！一番最初は背景クラスを示すので(0,0,0)にする\n",
    "colors = ((0,0,0),(255,0,0),(0,255,0),(0,0,255),(100,100,100),(50,50,50),(255,255,0),(255,0,255),(0,255,255),(100,100,0),(0,100,100))\n",
    "\n",
    "#ハイパーパラメータの指定\n",
    "epochs=3\n",
    "batch_size=2\n",
    "scale=3684#画像のスケール設定(縦の大きさを入力)\n",
    "\n",
    "\n",
    "#使用デバイスの確認\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(device)\n",
    "\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data_class=dataset_class\n",
    "data_class.insert(0, \"__background__\")\n",
    "classes = tuple(data_class)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def predict(model, device,dataloder):\n",
    "    Vdataiter=iter(dataloder)\n",
    "    vimg, vlabels = Vdataiter.next()\n",
    "    model.to(device)\n",
    "    with torch.no_grad():\n",
    "        vimg=vimg.to(device)\n",
    "        out = model(vimg)\n",
    "        #_, pre = torch.max(out.data, 1)\n",
    "        return out, vlabels"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_path=\"./bdetec/\"\n",
    "model=torch.load('bolt_detec.pt')\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "for imgfile in sorted(glob.glob(test_path+'/*')):\n",
    "\n",
    "    img = cv2.imread(imgfile)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    image_tensor = transforms.functional.to_tensor(img)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        prediction = model([image_tensor.to(device)])\n",
    "\n",
    "    for i,box in enumerate(prediction[0]['boxes']):\n",
    "        score = prediction[0]['scores'][i].cpu().numpy()\n",
    "        prebt, labebt = predict(net, 'cpu',bdetec_loader)\n",
    "        if score > 0.5:\n",
    "            score = round(float(score),2)\n",
    "            cat = prediction[0]['labels'][i].cpu().numpy()\n",
    "            txt = '{} {} Preload: {}kN'.format(classes[int(cat)], str(score),int(prebt))\n",
    "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "            cat_size = cv2.getTextSize(txt, font, 5, 10)[0]\n",
    "            c = colors[int(cat)]\n",
    "            box=box.cpu().numpy().astype('int')\n",
    "            cv2.rectangle(img, (box[0], box[1]), (box[2], box[3]), c , 2)\n",
    "            cv2.rectangle(img,(box[0], box[1] - cat_size[1] - 2),(box[0] + cat_size[0], box[1] - 2), c, -1)\n",
    "            cv2.putText(img, txt, (box[0], box[1] - 2), font, 5, (0, 0, 0), thickness=3, lineType=cv2.LINE_AA)\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(15,10))\n",
    "    plt.imshow(img)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "133b4a271e8e3ae036406f29ff3181f3cfc068360e0619bbcb9fcb8bbf692ed4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}